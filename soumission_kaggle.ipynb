{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargements des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.data as data\n",
    "import utils.model_utils as model_utils\n",
    "import utils.kaggle_submit as kaggle_submit\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\"train\": \"./res/train.csv\", \"test\": \"./res/test.csv\"}\n",
    "files[\"train\"] = data.open_otto_csv(files[\"train\"])\n",
    "files[\"test\"] = data.open_otto_csv(files[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = data.get_x_y(files[\"train\"])\n",
    "nb_class = len(train_y.unique())\n",
    "print(nb_class)\n",
    "testx = files[\"test\"].drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation ensemble apprentissage et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid, labels_train, labels_valid = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparatif sur quelques classifiers différents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.7739562191425366\n",
      "La log-loss est de :  2.3086776076579794\n",
      "evaluation (version Sam) : \n",
      "9662 / 12376\n",
      "Precision : 0.780705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(data_train, labels_train)\n",
    "\n",
    "y_pred3 = knn.predict(data_valid)\n",
    "y_pred3_probas = knn.predict_proba(data_valid)\n",
    "\n",
    "model_utils.evaluate_model(labels_valid, y_pred3, y_pred3_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission(knn, testx, \"res_knn.csv\", nb_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.6286302230265768\n",
      "La log-loss est de :  7.251880092416661\n",
      "evaluation (version Sam) : \n",
      "7684 / 12376\n",
      "Precision : 0.620879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(data_train, labels_train)\n",
    "\n",
    "y_pred4 = nb.predict(data_valid)\n",
    "y_pred4_probas = nb.predict_proba(data_valid)\n",
    "\n",
    "model_utils.evaluate_model(labels_valid, y_pred4, y_pred4_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission(nb, testx, \"res_GaussNaiveBayes.csv\", nb_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.690788007968747\n",
      "evaluation (version Sam) : \n",
      "8718 / 12376\n",
      "Precision : 0.704428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron_clf = Perceptron(max_iter = 1000)\n",
    "perceptron_clf.fit(data_train, labels_train)\n",
    "\n",
    "y_pred5 = perceptron_clf.predict(data_valid)\n",
    "\n",
    "model_utils.evaluate_model_Acc(labels_valid, y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : Regression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.7343083104433648\n",
      "La log-loss est de :  0.6699890545002816\n",
      "evaluation (version Sam) : \n",
      "9367 / 12376\n",
      "Precision : 0.756868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_clf = LogisticRegression(max_iter = 1000)\n",
    "logistic_clf.fit(data_train, labels_train)\n",
    "\n",
    "y_pred6 = logistic_clf.predict(data_valid)\n",
    "y_pred6_probas = logistic_clf.predict_proba(data_valid)\n",
    "\n",
    "model_utils.evaluate_model(labels_valid, y_pred6, y_pred6_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : SGDClassifier = modèle linéaire + descente de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.7216904073127184\n",
      "evaluation (version Sam) : \n",
      "9295 / 12376\n",
      "Precision : 0.751050\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD_clf = SGDClassifier(max_iter=1000)\n",
    "SGD_clf.fit(data_train, labels_train)\n",
    "\n",
    "y_predSGD = SGD_clf.predict(data_valid)\n",
    "\n",
    "model_utils.evaluate_model_Acc(labels_valid, y_predSGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : MLP Classifier : Multi-Layers-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.7776234266031896\n",
      "La log-loss est de :  0.5616724859868261\n",
      "evaluation (version Sam) : \n",
      "9718 / 12376\n",
      "Precision : 0.785229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(solver = 'sgd', hidden_layer_sizes = (30, 15), learning_rate = 'adaptive')\n",
    "mlp_clf.fit(data_train, labels_train)\n",
    "\n",
    "y_pred8 = mlp_clf.predict(data_valid)\n",
    "y_pred8_probas = mlp_clf.predict_proba(data_valid)\n",
    "\n",
    "model_utils.evaluate_model(labels_valid, y_pred8, y_pred8_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.8015505959705683\n",
      "La log-loss est de :  0.5783165926416591\n",
      "evaluation (version Sam) : \n",
      "10039 / 12376\n",
      "Precision : 0.811167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy.core.umath_tests import inner1d\n",
    "\n",
    "rnd_f = RandomForestClassifier(n_estimators = 250)\n",
    "rnd_f.fit(data_train, labels_train)\n",
    "\n",
    "y_pred9 = rnd_f.predict(data_valid)\n",
    "y_pred9_probas = rnd_f.predict_proba(data_valid)\n",
    "\n",
    "model_utils.evaluate_model(labels_valid, y_pred9, y_pred9_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission(rnd_f, testx, \"res_rndF.csv\", nb_class) # 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train du xgb...\n",
      "predict du xgb...\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(gamma = 0.03, learning_rate = 0.08, max_depth = 7, n_estimators = 250)\n",
    "print(\"train du xgb...\")\n",
    "xgb.fit(train_x, train_y)\n",
    "\n",
    "print(\"predict du xgb...\")\n",
    "# y_pred10 = xgb.predict(data_valid)\n",
    "y_pred10_probas = xgb.predict_proba(testx)\n",
    "\n",
    "# model_utils.evaluate_model(labels_valid, y_pred10, y_pred10_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission2(y_pred10_probas, 'xgb.csv', nb_class) # 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score precision : (version sklearn) 0.7793973092566393\n",
      "evaluation (version Sam) : \n",
      "9706 / 12376\n",
      "Precision : 0.784260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_Optim_clf = MLPClassifier(solver = 'sgd', hidden_layer_sizes = (50,), learning_rate = 'constant')\n",
    "mlp_clf.fit(data_train, labels_train)\n",
    "\n",
    "y_predOptimMLP = mlp_clf.predict(data_valid)\n",
    "y_predOptimMLP_proba = mlp_clf.predict_proba(data_valid)\n",
    "\n",
    "model_utils.evaluate_model(labels_valid, y_predOptimMLP, y_predOptimMLP_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mélange : MLPClassifier & RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144368, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy.core.umath_tests import inner1d\n",
    "\n",
    "mlp_clf = MLPClassifier(solver = 'sgd', hidden_layer_sizes = (30, 15), learning_rate = 'adaptive')\n",
    "mlp_clf.fit(train_x, train_y)\n",
    "\n",
    "rnd_f = RandomForestClassifier(n_estimators = 250)\n",
    "rnd_f.fit(train_x, train_y)\n",
    "\n",
    "y_predRndOptim = rnd_f.predict_proba(testx)\n",
    "y_predMlpOptim = mlp_clf.predict_proba(testx)\n",
    "\n",
    "y = 0.5*y_predRndOptim + 0.5*y_predMlpOptim\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission2(y, 'mlpRnd.csv', nb_class) # Kaggle : 0.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mélange : MLP & Random Forest + Calibrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy.core.umath_tests import inner1d\n",
    "\n",
    "mlp_clf = MLPClassifier(solver = 'sgd', hidden_layer_sizes = (30, 15), learning_rate = 'adaptive')\n",
    "rnd_f = RandomForestClassifier(n_estimators = 250)\n",
    "\n",
    "calibrated_mlp_clf = CalibratedClassifierCV(mlp_clf, method='isotonic', cv = 2)\n",
    "calibrated_rnd_f = CalibratedClassifierCV(rnd_f, method = 'isotonic', cv = 2)\n",
    "\n",
    "calibrated_mlp_clf.fit(train_x, train_y)\n",
    "calibrated_rnd_f.fit(train_x, train_y)\n",
    "\n",
    "y_predMlpCalibrated = calibrated_mlp_clf.predict_proba(testx)\n",
    "y_predRndFCalibrated = calibrated_rnd_f.predict_proba(testx)\n",
    "\n",
    "y = 0.5*y_predMlpCalibrated + 0.5*y_predRndFCalibrated\n",
    "\n",
    "# evaluate_model_prob(labels_valid, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144368, 9)\n"
     ]
    }
   ],
   "source": [
    "y2 = 0.2*y_predMlpCalibrated + 0.8*y_predRndFCalibrated\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission2(y, 'mlpRndCalibrated.csv', nb_class) # 0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission2(y2, 'mlpRndCalibrated.csv', nb_class) # 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mélange : Random Forest + MLP + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train du MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/biard/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train du Random Forest...\n",
      "train du XGBoost...\n",
      "prédiction MLP...\n",
      "prédiction Random Forest...\n",
      "prédiction XGBoost...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy.core.umath_tests import inner1d\n",
    "\n",
    "mlp_clf = MLPClassifier(solver = 'sgd', hidden_layer_sizes = (30, 15), learning_rate = 'adaptive')\n",
    "rnd_f = RandomForestClassifier(n_estimators = 250)\n",
    "xgb = XGBClassifier(gamma = 0.03, learning_rate = 0.08, max_depth = 7, n_estimators = 250)\n",
    "\n",
    "calibrated_mlp_clf = CalibratedClassifierCV(mlp_clf, method='isotonic', cv = 2)\n",
    "calibrated_rnd_f = CalibratedClassifierCV(rnd_f, method = 'isotonic', cv = 2)\n",
    "calibrated_xgb = CalibratedClassifierCV(xgb, method = 'isotonic', cv = 2)\n",
    "\n",
    "print(\"train du MLP...\")\n",
    "calibrated_mlp_clf.fit(train_x, train_y)\n",
    "print(\"train du Random Forest...\")\n",
    "calibrated_rnd_f.fit(train_x, train_y)\n",
    "print(\"train du XGBoost...\")\n",
    "calibrated_xgb.fit(train_x, train_y)\n",
    "\n",
    "print(\"prédiction MLP...\")\n",
    "y_predMlpCalibrated = calibrated_mlp_clf.predict_proba(testx)\n",
    "print(\"prédiction Random Forest...\")\n",
    "y_predRndFCalibrated = calibrated_rnd_f.predict_proba(testx)\n",
    "print(\"prédiction XGBoost...\")\n",
    "y_predXGBCalibrated = calibrated_xgb.predict_proba(testx)\n",
    "\n",
    "y = 0.2*y_predMlpCalibrated + 0.4*y_predRndFCalibrated + 0.4*y_predXGBCalibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit.make_csv_soumission2(y, 'RndF+MLP+XGBoost.csv', nb_class) # 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
